{"name":"Crawlable","tagline":"A way to make your web application crawlable, so it can be well referenced on the web. ","body":"# `Crawlable` is a way to render your web application as a static web site\r\n\r\nWhen you develop some cool features on a web project, there is a good chance that you do some ajax requests.\r\nIn the case you are developing a web application with `backbone.js` for example, you have no choice but to use the ajax\r\nfeature proposed by `jQuery`.\r\nSo you are developing some great stuffs, but if your project needs to be viewed on the web, you will wonder two things:\r\n\r\n* how is your work visible by google when it will try to reference it ? (is all the content always available, so it can be interpreted\r\nby google ?)\r\n* and how a visitor who doesn't have javascript support, or who have a slow computer will be able to navigate on it ?\r\n\r\n`Crawlable` could be your solution ! It is able to render your dynamic client side stuffs written with javascript, on the server side.\r\nBy this way, it can give a static cached html to your client, before any javascript code started to be executed on the web page.\r\n\r\nYou may say now, \"ok, but what if I have cached some dynamic content which could be updated at every time !?\".\r\n\r\n`Crawlable` doesn't simply cache html, it uses a module named [`Solidify`](https://github.com/trupin/solidify) to generate a derived version of your client side templates before storing it. When a client requests the server, Crawlable will feed the cached template with some updated data before giving it to you.\r\n\r\n## How does it works ?\r\n\r\nBefore explaining how all of this can be used, you need to understand how it works a little more deeply.\r\n\r\nHere are the steps `Crawlable` is going through to compute your final server side rendered html:\r\n\r\n* `Crawlable` demands to generate the cache for a specific page, so it asks to the router if it knows about a specific `pathname`. If the router says \"No !\", a 404 HTTP  (not found) error is returned, otherwise, Crawlable continues its work.\r\n* `Crawlable` then asks to `phantomjs` to render a page with a `pathname` for an `host`. At this time, `phantomjs` will query your server, with a special `user agent`, so it will know it's not a normal client.\r\n* The client side javascript is interpreted by `phantomjs`, and the templates are rendered in a special way, so `Crawlable` doesn't just get some html, rather a template compiled by `Solidify`.\r\n* Now `Crawlable` has this \"solidified\" template on the server side, it stores it, in order to be able to quickly refetch it at any time.\r\n* If a normal client queries the same page, `Crawlable` renders it on the server side, by feeding it with updated data. The \"solidified\" template actually contains metadata, so Crawlable knows where to fetch these updated data, with a specific session id if needed, etc...\r\n* Then, the rendered html can be injected in your web application page, so the final client will be able to see it right after the page has loaded.\r\n* If the client has a javascript support, your web application will replace this static html after it has loaded. If not, the client will simply be able to visit the page as if it was a static web site. That's why if this client was Google, javascript support activated or not, the content would always be visible to it. So your web application would be referenced in the same conditions than a classic static web site.\r\n \r\n## How do I use it ?\r\n\r\n `Crawlable` uses [`phantomjs`](http://phantomjs.org/) to render the web page on the server side, but you have no need to install it yourself,\r\nthe installer takes care of it for you.\r\n\r\nBut, `phantomjs` uses `python`. So you should have it installed to make the whole thing work.\r\n\r\nThen, install it like this:\r\n\r\n`npm install crawlable --save`\r\n\r\nAt this time, `Crawlable` is very convenient to use with the great `Express` and `Connect` modules.\r\nAs we saw above, `Crawlable` is not simply a server side module, but also a client side library.\r\n\r\nOn the client side, you would use it with the `JQuery` plugin named `jquery.crawlable.js`. This plugin depends on\r\nthe `Solidify` plugin named `jquery.solidify.js`, which also depends on the `Handlebars` template engine and `JQuery`.\r\n\r\nSo you would include something like this in your html:\r\n\r\n``` html\r\n\t<script type=\"text/javascript\" src=\"/jquery.js\"></script>\r\n\t<script type=\"text/javascript\" src=\"/handlebars.js\"></script>\r\n\t<script type=\"text/javascript\" src=\"/jquery.solidify.js\"></script>\r\n\t<script type=\"text/javascript\" src=\"/jquery.crawlable.js\"></script>\r\n```\r\n\r\n### So, how do I use it on the server side with `Express` ?\r\n\r\nHere is the code you could use in your `app.js` file:\r\n\r\n``` js\r\n\tvar express = require('express'),\r\n\t\tCrawlable = require('crawlable');\r\n\r\n\t// this is the host that crawlable will query to render the pages.\r\n\tvar host = 'http://127.0.0.1:' + (process.env.PORT || 5000);\r\n\r\n\t// create a new crawlable instance\r\n\tvar crawlable = Crawlable.create({ host: host });\r\n\r\n\t// create your express application\r\n\tvar app = express();\r\n\r\n\t// configure it\r\n    app.configure(function () {\r\n\t\t// this middleware catches when crawlable is requesting your server\r\n        app.use(crawlable._solidify.express());\r\n    });\r\n\r\n\t// start crawlable\r\n\tcrawlable.start(function (err) {\r\n\t\tif (err) return console.log(err);\r\n\r\n\t\t// register a route. in that case it is the only route available from the crawlable router\r\n\t\tcrawlable.route('/', function (err) {\r\n\t\t\tif (err) return console.log(err);\r\n\r\n\t\t\t// register your express main route. don't forget the crawlable middleware, which will handle\r\n\t\t\t// the cached html content, and generate it if it doesn't exists.\r\n\t\t\tapp.get('*', crawlable.express(), function (req, res) {\r\n\t\t\t\t// here you can do what you want to render your application.\r\n\t\t\t\t// you can access the rendered html like this: req.crawlable.html\r\n\t\t\t\t// for example:\r\n                // res.render('app.html', { staticApp: req.crawlable.html });\r\n            });\r\n\r\n\t\t\t// start your application\r\n\t        app.listen(url.parse(host).port);\r\n\r\n\t\t\t// generate the cache for every registered routes,so the first client will be able to access the static html.\r\n\t\t\tcrawlable.crawl();\r\n\t\t});\r\n\t});\r\n\r\n```\r\n\r\nThen, admitting you are using `Handlebars` as a template engine, here is what you could have as `index.html` file:\r\n\r\n``` html\r\n\t<html>\r\n\t\t<head>...</head>\r\n\t\t<body>\r\n\t\t\t<!-- Where you put your static application content at the first place. -->\r\n\t\t\t<div id=\"app\">{{{ staticApp }}}</div>\r\n\r\n\t\t\t<!-- JS libraries -->\r\n            <script type=\"text/javascript\" src=\"/jquery/jquery.js\"></script>\r\n            <script type=\"text/javascript\" src=\"/handlebars/handlebars.js\"></script>\r\n            <script type=\"text/javascript\" src=\"/underscore/underscore.js\"></script>\r\n\t        <script type=\"text/javascript\" src=\"/backbone/backbone.js\"></script>\r\n            <script type=\"text/javascript\" src=\"/backbone.babysitter/lib/backbone.babysitter.js\"></script>\r\n            <script type=\"text/javascript\" src=\"/backbone.wreqr/lib/backbone.wreqr.js\"></script>\r\n            <script type=\"text/javascript\" src=\"/marionette/lib/backbone.marionette.js\"></script>\r\n            <script type=\"text/javascript\" src=\"/solidify/jquery.solidify.js\"></script>\r\n            <script type=\"text/javascript\" src=\"/crawlable/jquery.crawlable.js\"></script>\r\n\r\n            <!-- Application sources -->\r\n            <script type=\"text/javascript\" src=\"/app.js\"></script>\r\n\t\t</body>\r\n\t</html>\r\n```\r\n\r\n### How do I make my client side javascript compatible ?\r\n\r\nWhat happen now on the client side ? Here is what you could have in your `app.js` file:\r\n\r\n``` js\r\n\t// Be sure to use the solidify template engine.\r\n\tBackbone.Marionette.TemplateCache.prototype.compileTemplate = function (rawTemplate) {\r\n        return Backbone.$.solidify(rawTemplate);\r\n    };\r\n\r\n\t// Create a Marionette application (it could be Backbone.js or whatever you want).\r\n\tvar app = new Marionette.Application();\r\n\r\n\t// Initialize it.\r\n\tapp.addInitializer(function () {\r\n\t\t// do something ...\r\n\t});\r\n\r\n\t$(document).ready(function () {\r\n\r\n\t\t// Initialize your main application anchor with crawlable.\r\n\t\t// It says to crawlable to wait for the application to be fully loaded, before inject the code\r\n\t\t// into the <div id=\"#app\">.\r\n\t\t// The context option is the initial state with which the application should start.\r\n        $('#app').crawlable({\r\n            context: '<div class=\"container-fluid\"></div>'\r\n        });\r\n\r\n\t\t// Simply start your application.\r\n        app.start();\r\n\r\n\t});\r\n```\r\n\r\nAt this point, the peace of code we seen is able to load an application in front of its ```Crawlable``` static part.\r\nBut what if we want to create some dynamic content, and cache it with ```Crawlable```?\r\n\r\nImagine now you want to render a list. You would have a `Collection` and a `View`, rendering an `ItemView` for each\r\n`Model` of your `Collection`.\r\n\r\nBy using some `Handlebars` templates, see how you would do (notice there is no need to modify your javascript code\r\nto make it compatible with `Crawlable`, only your templates).\r\n\r\nHere is the `Item` template:\r\n\r\n``` html\r\n\t<!-- specify the needed request to fetch the data -->\r\n\t{{solidify \"/api/items\"}}\r\n\t<!-- the same as {{#each}}, but for the server side rendering only (client will ignore it) -->\r\n\t{{#solidify-each \"this\"}}\r\n\t\t<!-- dereference the field content, will be interpreted on the client and server side -->\r\n\t\t<li>{ {content} }</li>\r\n\t{{/solidify-each}}\r\n```\r\n\r\nNow here is the `List` template:\r\n\r\n``` html\r\n\t<div>\r\n\t\t<h1>My list</h1>\r\n\t\t<div>\r\n\t\t\t<!-- Include a template. This is for the server side only, the client simply ignore it -->\r\n\t\t\t{{solidify-include \"/templates/item.html\"}}\r\n\t\t</div>\r\n\t</div>\r\n```\r\n\r\nAs you can see, you just have to respect some extra rules to make your template understandable by `Crawlable`.\r\nYou can see the `Solidify` documentation for details, but here is what you need for now:\r\n\r\n* `{{solidify [\"method\"] \"/my/api/route\"}}` specifies a request to do when `Crawlable` will need some data to feed the template\r\n(on the server side only).\r\n* `{{solidify-include \"/my/template/path\"}}` specifies a template to include (on the server side only).\r\n* `{{[#]solidify-helperName}}` calls an helper (on the server side only).\r\n* `{ {[#]helperName} }` calls an helper (on the client and server side).\r\n* `{ {fieldName} }` dereferences a field (on the client and server side).\r\n\r\nNotice that every other `Handlebars` syntax are available, and all the syntax we saw which are used on the server side\r\nonly, are completely ignored by `Solidify` on the client side, so it has no influence on your client side original template.\r\n\r\n## Options\r\n\r\n`Crawlable` provides the following configuration options:\r\n\r\n* `logger`: a winston logger instance to provide a way to log.\r\n* `Persistence`: a `Persistence` class to provide a way to store data. Defaults to `NeDb`.\r\n* `persistenceOptions`: an object containing the `persistence` options used at instantiation.\r\n* `cacheTtl`: the cache entry time to live in seconds. Defaults to one hour.\r\n* `Renderer`: the `Renderer` class to provide a way to render a webpage. Defaults to `DefaultRenderer`.\r\n* `rendererOptions`: an object containing the `renderer` options used at instantiation.\r\n* `concurrency`: the max amount of pages it can process at the same time. Defaults to 10.\r\n\r\n## What technologies does it use and why ?\r\n\r\n`Crawlable` uses the excellent [`PhantomJS`](http://phantomjs.org/) through a bridge, implemented in the node module [`phantom`](https://github.com/sgentle/phantomjs-node)\r\nIt is light because only one `PhantomJS` process is used. This process runs like a \"page pool\", meaning that an amount of\r\npages is launched at the start and only these `PhantomJS` pages are used to render the html.\r\nBy doing this way, `Crawlable` saves a lot of memory and can consider doing some efficient parallel renderings.\r\n\r\n`Crawlable` also uses [`nedb`](https://github.com/louischatriot/nedb) by default to store data.\r\nThis can handle an \"in memory\" and a \"persistent\" storing. It is also totally embedded and very light.\r\n\r\n## Want an example ?\r\n\r\n* You can check the todos example on `github`: https://github.com/trupin/crawlable-todos\r\n* Or visit it deployed on `heroku`: http://crawlable-todos.herokuapp.com/\r\n","google":"crawlable, crawling, ajax, google, indexing, SEO, Search Engine Optimization","note":"Don't delete this file! It's used internally to help with page regeneration."}